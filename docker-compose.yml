services:
  train-sft:
    build:
      context: .
      dockerfile: Dockerfile
    image: reasoning-tool-llm-agent-v2

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    volumes:
      - ./rlm/weights:/app/rlm/weights
      - ./hf_cache:/root/.cache/huggingface

    environment:
      - SFT_MODEL_PATH=/app/rlm/weights/sft_lora
      - HF_HOME=/root/.cache/huggingface

    working_dir: /app
    command: ["python3", "rlm/train_sft.py"]

  train-grpo:
    build:
      context: .
      dockerfile: Dockerfile
    image: reasoning-tool-llm-agent-v2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./rlm/weights:/app/rlm/weights
      - ./weights:/app/weights
      - ./hf_cache:/root/.cache/huggingface
    environment:
      - SFT_MODEL_PATH=/app/rlm/weights/sft_lora
      - FINAL_MODEL_PATH=/app/weights/final_rlm_lora
      - HF_HOME=/root/.cache/huggingface
    working_dir: /app
    command: ["python3", "rlm/train_grpo.py"]

  inference-rlm:
    build:
      context: .
      dockerfile: Dockerfile
    image: reasoning-tool-llm-agent-v2
    ports:
      - "8002:8000"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    volumes:
      - ./rlm/weights:/app/rlm/weights
      - ./weights:/app/weights
      - ./hf_cache:/root/.cache/huggingface

    environment:
      - SFT_MODEL_PATH=/app/rlm/weights/sft_lora
      - FINAL_MODEL_PATH=/app/weights/final_rlm_lora
      - HF_HOME=/root/.cache/huggingface

    working_dir: /app
    command: ["python3", "api/app.py"]

  bash-rlm:
    build:
      context: .
      dockerfile: Dockerfile
    image: reasoning-tool-llm-agent-v2

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    volumes:
      - ./rlm/weights:/app/rlm/weights
      - ./weights:/app/weights
      - ./hf_cache:/root/.cache/huggingface

    environment:
      - SFT_MODEL_PATH=/app/rlm/weights/sft_lora
      - FINAL_MODEL_PATH=/app/weights/final_rlm_lora
      - HF_HOME=/root/.cache/huggingface

    working_dir: /app
    command: ["bash"]