services:
  reasoning-tool-llm-agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: reasoning-tool-llm-agent
    image: reasoning-tool-llm-agent:latest

    # GPU support (using runtime for compatibility)
    runtime: nvidia

    # Environment variables
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # CUDA_VISIBLE_DEVICES will be set automatically by docker-entrypoint.sh
      # based on GPU with highest available memory
      - PYTHONUNBUFFERED=1
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda-12.8/lib64:/usr/lib/x86_64-linux-gnu

    # Volume mounts
    volumes:
      # Mount code directory for easy editing
      - ./:/app

    # Working directory
    working_dir: /app

    # Keep container running
    stdin_open: true
    tty: true
    # ports:
    #   - "8888:8888"
    command: bash
    # command: jupyter notebook --ip=0.0.0.0 --no-browser --allow-root
    # Network mode (optional, can be removed if not needed)
    network_mode: bridge

    # Restart policy
    restart: unless-stopped
